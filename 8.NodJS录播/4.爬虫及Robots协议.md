#爬虫及Robots协议

    爬虫,是一种自动获取网页内容的程序。是搜索引擎的重要组成部分,因此搜索引擎优化很大程度上就是针对爬虫而做出的优化。

    robots.txt是一个文本文件,robots.txt是一个协议,不是一个命令。robots.txt是爬虫要查看的第一个文件。robots.txt文件告诉爬虫再服务器上什么文件是可以被查看的,搜索机器人j就会按照该文件中的内容来确定访问的范围

    Express
    Request
    Cheerio


    comet http长链接
    ob_flush()
    flush()

    基于websocket的解决方案

    socket.io

    SSE(Server-Send Event)
    服务器推送数据的新方式